{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facial_expression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "f5Z6aDpc2Ajr",
        "colab_type": "code",
        "outputId": "597a9bb4-c2ab-4147-ca64-9159463b1886",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Extra Setup for Colaboratory\n",
        "'''\n",
        "#!pip install cmake\n",
        "#!pip install dlib\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# uploading into Colaboratory is so freaking slow...\n",
        "# compressing everything into one file to reduce the time wasted on uploading\n",
        "uploaded = files.upload() \n",
        "#!7za x colaboratory_dependencies.7z"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96ea83f9-0fab-42f8-af78-ec6c6b6aa375\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-96ea83f9-0fab-42f8-af78-ec6c6b6aa375\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving facial_feature_detector.py to facial_feature_detector.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lScQSX8fxEk1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Libraries, etc.\n",
        "'''\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np \n",
        "import scipy as sp\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "from math import sqrt\n",
        "import scipy.io as io\n",
        "import tensorflow as tf \n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils as npu\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Convolution2D, Activation, BatchNormalization, GaussianNoise, MaxPooling2D, Dropout, Dense, Flatten\n",
        "  \n",
        "\n",
        "\n",
        "import frontalize\n",
        "import check_resources as check\n",
        "import camera_calibration as calib\n",
        "import facial_feature_detector as feature_detection\n",
        "\n",
        "from models import get_model1, get_model2, get_model3\n",
        "\n",
        "#this_path = os.path.dirname(os.path.abspath(__file__)) \n",
        "this_path = str(Path().resolve()) # for Colaboratory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TkgKeBTN2AkN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Constants, Hyperparameters, etc.\n",
        "'''\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 64\n",
        "\n",
        "input_file = 'fer2013.csv'\n",
        "filepath = 'Model.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
        "\n",
        "model1_acc_file = \"acc_model1_t2.png\"\n",
        "model2_acc_file = \"acc_model2_t2.png\"\n",
        "model3_acc_file = \"acc_model3_t2.png\"\n",
        "acc_file = model1_acc_file\n",
        "\n",
        "model1_loss_file = \"loss_model1_t2.png\"\n",
        "model2_loss_file = \"loss_model2_t2.png\"\n",
        "model3_loss_file = \"loss_model3_t2.png\"\n",
        "loss_file = model1_loss_file\n",
        "\n",
        "model1_cm_file = \"cm_model1_t2.png\"\n",
        "model2_cm_file = \"cm_model2_t2.png\"\n",
        "model3_cm_file = \"cm_model3_t2.png\"\n",
        "cm_file = model1_cm_file\n",
        "\n",
        "emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
        "num_classes = len(emotion_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8FQmQZh62Akf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "8de39d5b-cb3e-4505-9f8f-5b0725f96ce8"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Load & Parse Data into Training/Test Labels & Images\n",
        "'''\n",
        "data = pd.read_csv(input_file)\n",
        "data.head()\n",
        "\n",
        "# get data and labels\n",
        "train_set = data[(data.Usage == 'Training')]\n",
        "validation_set = data[(data.Usage == 'PublicTest')]\n",
        "test_set = data[(data.Usage == 'PrivateTest')]\n",
        "\n",
        "# greyscale so depth 1\n",
        "depth = 1\n",
        "height = int(sqrt(len(data.pixels[0].split())))\n",
        "width = height\n",
        "\n",
        "# from pandas to np array\n",
        "X_train = np.array(list(map(str.split, train_set.pixels)), np.uint8)\n",
        "X_validation = np.array(list(map(str.split, validation_set.pixels)), np.uint8)\n",
        "X_test = np.array(list(map(str.split, test_set.pixels)), np.uint8)\n",
        "\n",
        "# reshape data\n",
        "num_train = X_train.shape[0]\n",
        "num_validation = X_validation.shape[0]\n",
        "num_test = X_test.shape[0]\n",
        "\n",
        "X_train = X_train.reshape(num_train, width, height, depth)\n",
        "X_validation = X_validation.reshape(num_validation, width, height, depth)\n",
        "X_test = X_test.reshape(num_test, width, height, depth)\n",
        "\n",
        "y_train = train_set.emotion\n",
        "y_validation = validation_set.emotion\n",
        "y_test = test_set.emotion\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_validation = np_utils.to_categorical(y_validation, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# print shapes\n",
        "print('X_training: ', X_train.shape)\n",
        "print('X_validation: ', X_validation.shape)\n",
        "print('X_test: ', X_test.shape)\n",
        "print( )\n",
        "print('y_training: ', y_train.shape)\n",
        "print('y_validation: ', y_validation.shape)\n",
        "print('y_test: ', y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_training:  (28709, 48, 48, 1)\n",
            "X_validation:  (3589, 48, 48, 1)\n",
            "X_test:  (3589, 48, 48, 1)\n",
            "\n",
            "y_training:  (28709, 7)\n",
            "y_validation:  (3589, 7)\n",
            "y_test:  (3589, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HnMU3nsV9LMl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Frontalization Function\n",
        "'''\n",
        "def myfrontalize(X, limit):\n",
        "  count = 0\n",
        "  print(\"Total Images: \", limit)\n",
        "  for i in range(0, limit):\n",
        "    print(\"\\r\", end='')\n",
        "    print(\"Images Completed: {0}\".format(i), end='', flush=True)\n",
        "\n",
        "    img = X[i, :, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    img = img.astype(np.uint8)\n",
        "\n",
        "    # check for dlib saved weights for face landmark detection\n",
        "    # if it fails, dowload and extract it manually from\n",
        "    # http://sourceforge.net/projects/dclib/files/dlib/v18.10/shape_predictor_68_face_landmarks.dat.bz2\n",
        "    check.check_dlib_landmark_weights()\n",
        "    \n",
        "    # load detections performed by dlib library on 3D model and Reference Image\n",
        "    model3D = frontalize.ThreeD_Model(this_path + \"/frontalization_models/model3Ddlib.mat\", 'model_dlib')\n",
        "    \n",
        "    # extract landmarks from the query image\n",
        "    # list containing a 2D array with points (x, y) for each face detected in the query image\n",
        "    lmarks = feature_detection.get_landmarks(img)\n",
        "    if type(lmarks) is np.ndarray:\n",
        "      \n",
        "      # perform camera calibration according to the first face detected\n",
        "      proj_matrix, camera_matrix, rmat, tvec = calib.estimate_camera(model3D, lmarks[0])\n",
        "      \n",
        "      # load mask to exclude eyes from symmetry\n",
        "      eyemask = np.asarray(io.loadmat('frontalization_models/eyemask.mat')['eyemask'])\n",
        "      \n",
        "      # perform frontalization\n",
        "      frontal_raw, frontal_sym = frontalize.frontalize(img, proj_matrix, model3D.ref_U, eyemask)\n",
        "\n",
        "      # resize and convert image to grayscale\n",
        "      temp = cv2.resize(frontal_sym, dsize=(48, 48), interpolation=cv2.INTER_CUBIC)\n",
        "      temp = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)   \n",
        "      temp = np.resize(temp, (48, 48, 1))\n",
        "      \n",
        "      X[i, :, :, :] = temp.astype(np.float32)\n",
        "      \n",
        "      count += 1\n",
        "      \n",
        "  print('{} images out of {} were frontalized.'.format(count, limit))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wTDNwnW2EY4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "53bb87b9-5f04-4fbe-dca6-a2b3b6135b44"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Histogram Equalization - Not defined as method, because \n",
        "train has a special case to catch and delete harmful inputs\n",
        "'''\n",
        "clahe = cv2.createCLAHE(clipLimit=3.235, tileGridSize=(5,5))\n",
        "\n",
        "# original image set\n",
        "X_train1 = X_train.copy() \n",
        "X_val1 = X_validation.copy()\n",
        "X_test1 = X_test.copy()\n",
        "\n",
        "# linear histogram equalization set\n",
        "X_train2 = X_train.copy() \n",
        "X_val2 = X_validation.copy()\n",
        "X_test2 = X_test.copy()\n",
        "\n",
        "# clahe set\n",
        "X_train3 = X_train.copy()\n",
        "X_val3 = X_validation.copy()\n",
        "X_test3 = X_test.copy()\n",
        "\n",
        "# frontalized set\n",
        "X_train4 = X_train.copy()\n",
        "X_val4 = X_validation.copy()\n",
        "X_test4 = X_test.copy()\n",
        "\n",
        "# histogram equalization (primarily) for sets 2, 3\n",
        "i = 0\n",
        "while (i < num_train):\n",
        "  tMax = X_train1[i].max()\n",
        "  tMin = X_train1[i].min()  \n",
        "\n",
        "  if (tMax > tMin):\n",
        "    tRatio = 255 / (tMax - tMin)\n",
        "    X_train2[i] = np.multiply((X_train1[i] - tMin), tRatio)\n",
        "    \n",
        "  # Delete harmful training examples from X_train\n",
        "  else:\n",
        "    X_train1 = np.delete(X_train1, (i), axis=0)\n",
        "    X_train2 = np.delete(X_train2, (i), axis=0)\n",
        "    X_train3 = np.delete(X_train3, (i), axis=0)\n",
        "    X_train4 = np.delete(X_train4, (i), axis=0)\n",
        "    y_train = np.delete(y_train, (i), axis=0)\n",
        "    num_train -= 1\n",
        "    i -= 1\n",
        "    \n",
        "  X_train3[i] = clahe.apply(X_train2[i])[:,:,np.newaxis]\n",
        "  i += 1\n",
        "  \n",
        "i = 0\n",
        "while (i < num_validation):\n",
        "  tMax = X_val1[i].max()\n",
        "  tMin = X_val1[i].min()\n",
        "\n",
        "  if (tMax > tMin):\n",
        "    tRatio = 255 / (tMax - tMin)\n",
        "    X_val2[i] = np.multiply((X_val1[i] - tMin), tRatio).round()\n",
        "    \n",
        "  # Shouldn't delete validation data... skip so we don't divide by 0\n",
        "  else:\n",
        "    X_val2[i] = X_val1[i]\n",
        "\n",
        "  X_val3[i] = clahe.apply(X_val2[i])[:,:,np.newaxis]\n",
        "  i += 1\n",
        "\n",
        "i = 0\n",
        "while (i < num_test):\n",
        "  tMax = X_test1[i].max()\n",
        "  tMin = X_test1[i].min()\n",
        "\n",
        "  if (tMax > tMin):\n",
        "    tRatio = 255 / (tMax - tMin)\n",
        "    X_test2[i] = np.multiply((X_test1[i] - tMin), tRatio).round()\n",
        "    \n",
        "  # Shouldn't delete test data... skip so we don't divide by 0\n",
        "  else:\n",
        "    X_test2[i] = X_test1[i]\n",
        "    \n",
        "  X_test3[i] = clahe.apply(X_test2[i])[:,:,np.newaxis]\n",
        "  i += 1\n",
        "  \n",
        "# apply frontalization\n",
        "print(\"Attempting to frontalize image data...\")\n",
        "myfrontalize(X_train4, num_train)\n",
        "myfrontalize(X_val4, num_validation)\n",
        "myfrontalize(X_test4, num_test)\n",
        "\n",
        "\n",
        "# print examples from each set\n",
        "print('Original Images')\n",
        "for x in range(1,6):\n",
        "    plt.subplot(1, 5, x)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(X_test1[x], cmap='gray')\n",
        "    \n",
        "plt.show()\n",
        "\n",
        "print('Original w/ Linear Transform to normalize pixel values')\n",
        "for x in range(1,6):\n",
        "    plt.subplot(1, 5, x)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(X_test2[x], cmap='gray')\n",
        "    \n",
        "plt.show()\n",
        "\n",
        "print('Normalized w/ Contrast Limited Adaptive Histogram Equalization')\n",
        "for x in range(1,6):\n",
        "    plt.subplot(1, 5, x)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(X_test3[x], cmap='gray')\n",
        "    \n",
        "plt.show() \n",
        "\n",
        "plt.figure()\n",
        "plt.title('Frontalized Images')\n",
        "for x in range(1,6):\n",
        "  plt.subplot(1, 5, x)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(X_test4[x, :, :, 0], cmap='gray') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempting to frontalize image data...\n",
            "Number of images:\n",
            "28654\n",
            "7795 images complete"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "60ZKSuYdC-_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save('X_train_frontalized', X_train4)\n",
        "np.save('X_val_frontalized', X_val4)\n",
        "np.save('X_test_frontalized', X_test4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdpT7cRf9_BQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "TensorFlow Model(s)\n",
        "'''\n",
        "\n",
        "# shallow model\n",
        "def get_model1():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Convolution2D(64, (3, 3), padding='same', input_shape=(48,48,1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Convolution2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Convolution2D(256, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Convolution2D(512, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Dense(256))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Dense(7))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "# actual model\n",
        "def get_model2():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Convolution2D(64, (3, 3), padding='same', input_shape=(48,48,1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Convolution2D(128, (5, 5), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Convolution2D(512, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Convolution2D(512, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Dense(7))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "# deeper model\n",
        "def get_model3():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Convolution2D(64, (3, 3), padding='same', input_shape=(48,48,1)))\n",
        "  model.add(Convolution2D(64, (3, 3), padding='same')) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  #model.add(GaussianNoise(2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Convolution2D(128, (3, 3), padding='same'))\n",
        "  model.add(Convolution2D(128, (3, 3), padding='same')) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  #model.add(GaussianNoise(2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Convolution2D(256, (3, 3), padding='same'))\n",
        "  model.add(Convolution2D(265, (3, 3), padding='same')) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  #model.add(GaussianNoise(2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Convolution2D(512, (3, 3), padding='same'))\n",
        "  model.add(Convolution2D(512, (3, 3), padding='same')) \n",
        "  model.add(Convolution2D(512, (1, 1), padding='same')) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n",
        "  #model.add(GaussianNoise(2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(2048))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Dense(7))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pf_ribmHP4yy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Metric(s)\n",
        "'''\n",
        "\n",
        "# metric to balance precision and recall\n",
        "def fbeta(y_true, y_pred, threshold_shift=0):\n",
        "  beta = 1\n",
        "\n",
        "  # just in case of hipster activation at the final layer\n",
        "  y_pred = K.clip(y_pred, 0, 1)\n",
        "\n",
        "  # shifting the prediction threshold from .5 if needed\n",
        "  y_pred_bin = K.round(y_pred + threshold_shift)\n",
        "\n",
        "  tp = K.sum(K.round(y_true * y_pred_bin), axis=1) + K.epsilon()\n",
        "  fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)), axis=1)\n",
        "  fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
        "\n",
        "  precision = tp / (tp + fp)\n",
        "  recall = tp / (tp + fn)\n",
        "\n",
        "  beta_squared = beta ** 2\n",
        "  return K.mean((beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "okS6IyqTNprE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Prepare Model for Training\n",
        "'''\n",
        "# assign the desired model from above\n",
        "model = get_model1()\n",
        "model.summary()\n",
        "\n",
        "# assign X to the desired image set(s) from above\n",
        "X_train = X_train3\n",
        "X_validation = X_validation3\n",
        "X_test = X_test3\n",
        "\n",
        "num_train = len(X_train)\n",
        "\n",
        "# reshape X to expected shape and cast it back to type float32\n",
        "X_train = X_train.reshape(num_train,width,height,1).astype(np.float32)\n",
        "X_validation = X_validation.reshape(num_validation,width,height,1).astype(np.float32)\n",
        "X_test = X_test.reshape(num_test,width,height,1).astype(np.float32)\n",
        "\n",
        "# augment and fit data\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.0,\n",
        "    height_shift_range=0.0,\n",
        "    shear_range=0,\n",
        "    zoom_range=0.0,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False)\n",
        "datagen.fit(X_train)\n",
        "datagen.fit(X_validation)\n",
        "\n",
        "# to be applied during training\n",
        "checkpointer = ModelCheckpoint(\n",
        "    filepath, monitor='val_loss', verbose=1, \n",
        "    save_best_only=False, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.1, \n",
        "    patience=10, verbose=0, mode='auto', \n",
        "    min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=0, \n",
        "    verbose=0, mode='auto')\n",
        "\n",
        "# prepare model to train\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=[fbeta, 'accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I8sEsNIkRRUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Training\n",
        "'''\n",
        "train_flow = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "validation_flow = datagen.flow(X_validation, y_validation)\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_flow,\n",
        "    steps_per_epoch= num_train / BATCH_SIZE,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    verbose=1,\n",
        "    validation_data=validation_flow,\n",
        "    validation_steps=num_validation / BATCH_SIZE,\n",
        "    callbacks=[checkpointer, reduce_lr, checkpointer]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-skX4SpGSeIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Evaluate Test Set & Print Results\n",
        "'''\n",
        "score = model.evaluate(X_test, y_test, steps=int(num_test / BATCH_SIZE))\n",
        "print('Evaluation Loss: ', score[0])\n",
        "print('Evaluation Accuracy: ', score[1])\n",
        "\n",
        "# History of Accuracy\n",
        "fig1 = plt.figure()\n",
        "fig1.plot(history.history['acc'], color='b', label='Training')\n",
        "fig1.plot(history.history['val_acc'], color='g', label='Validation')\n",
        "fig1.title('History for Accuracy')\n",
        "fig1.ylabel('Accuracy')\n",
        "fig1.xlabel('Epoch')\n",
        "fig1.legend(loc='upper left')\n",
        "fig1.savefig(acc_file)\n",
        "fig1.show() \n",
        "\n",
        "# History of Loss\n",
        "fig2 = plt.figure()\n",
        "plt.plot(history.history['loss'], color='b', label='Training')\n",
        "plt.plot(history.history['val_loss'], color='g', label='Validation')\n",
        "plt.title('History for Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='lower left')\n",
        "fig2.savefig(loss_file)\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = model.predict_classes(X_test)\n",
        "y_true = np.asarray([np.argmax(i) for i in y_test])\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "ax = sns.heatmap(\n",
        "    cm_norm, annot=True, linewidths=0, square=False, cmap='Greens', \n",
        "    yticklabels=emotion_labels, xticklabels=emotion_labels, \n",
        "    vmin=0, vmax=np.max(cm_norm), fmt='.2f', \n",
        "    annot_kws={'size': 20}\n",
        ")\n",
        "ax.set(xlabel='Predicted Label', ylabel='Actual Label')\n",
        "plt.savefig(cm_file)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}